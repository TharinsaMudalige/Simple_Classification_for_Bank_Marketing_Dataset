{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn3qNueXcDxmqRM6i+qzqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Simple_Classification_for_Bank_Marketing_Dataset/blob/main/Machine_Learning_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7SdmO1K3pJ8",
        "outputId": "33de8284-ff56-4e86-9768-cd43914e97a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "x2hy5oBiEsTh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/ML Coursework/bank-additional-full.csv'\n",
        "\n",
        "# Loading the CSV file into a Pandas DataFrame\n",
        "data = pd.read_csv(file_path, delimiter=';')\n",
        "# Displaying the first few rows\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQosKmo-Epsu",
        "outputId": "02a5a046-98e0-4af4-9b26-82e840c1fcdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age        job  marital    education  default housing loan    contact  \\\n",
            "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
            "1   57   services  married  high.school  unknown      no   no  telephone   \n",
            "2   37   services  married  high.school       no     yes   no  telephone   \n",
            "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
            "4   56   services  married  high.school       no      no  yes  telephone   \n",
            "\n",
            "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
            "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0          93.994          -36.4      4.857       5191.0  no  \n",
            "1          93.994          -36.4      4.857       5191.0  no  \n",
            "2          93.994          -36.4      4.857       5191.0  no  \n",
            "3          93.994          -36.4      4.857       5191.0  no  \n",
            "4          93.994          -36.4      4.857       5191.0  no  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initial dataset shape:\", data.shape)"
      ],
      "metadata": {
        "id": "I1-kdrn2Ff4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c9dbf2-fef4-47db-eb55-aa6c27aebd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial dataset shape: (41188, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "K6edOIT7Ta3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "1.   Handling \"unknown values\"\n",
        "2.   Handling the value of pdays\n",
        "\n",
        "1.   Handling duplicate rows\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6tZqeScoJ9cJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns containing unknown values\n",
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
        "\n",
        "# Handling \"unknown\" values\n",
        "for column in categorical_columns:\n",
        "    unknown_count = data[column].value_counts().get('unknown', 0)\n",
        "    print(f'\"unknown\" count in {column}: {unknown_count}')\n",
        "\n",
        "    if column in ['default', 'education']:  # Taking \"unknown\" as a separate category\n",
        "        data[column] = data[column].replace('unknown', 'unknown')\n",
        "    else:  # Replace \"unknown\" with the mode for other columns\n",
        "        data[column] = data[column].replace('unknown', data[column].mode()[0])\n",
        "\n",
        "# Replacing 999 with -1 as \"not contacted\"\n",
        "data['pdays'] = data['pdays'].replace(999, -1)\n",
        "\n",
        "# Removing duplicate rows\n",
        "data = data.drop_duplicates()\n",
        "\n",
        "print(\"Final dataset shape after cleaning:\", data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR3O7sSSOBHB",
        "outputId": "39949d73-595b-4e8f-92c4-9c221fa74fb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"unknown\" count in job: 330\n",
            "\"unknown\" count in marital: 80\n",
            "\"unknown\" count in education: 1731\n",
            "\"unknown\" count in default: 8597\n",
            "\"unknown\" count in housing: 990\n",
            "\"unknown\" count in loan: 990\n",
            "Final dataset shape after cleaning: (41176, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDm9-LOlOfxH",
        "outputId": "2d1a0362-733f-47aa-e11e-8b9077228f3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age        job  marital    education  default housing loan    contact  \\\n",
            "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
            "1   57   services  married  high.school  unknown      no   no  telephone   \n",
            "2   37   services  married  high.school       no     yes   no  telephone   \n",
            "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
            "4   56   services  married  high.school       no      no  yes  telephone   \n",
            "\n",
            "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
            "0   may         mon  ...         1     -1         0  nonexistent          1.1   \n",
            "1   may         mon  ...         1     -1         0  nonexistent          1.1   \n",
            "2   may         mon  ...         1     -1         0  nonexistent          1.1   \n",
            "3   may         mon  ...         1     -1         0  nonexistent          1.1   \n",
            "4   may         mon  ...         1     -1         0  nonexistent          1.1   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0          93.994          -36.4      4.857       5191.0  no  \n",
            "1          93.994          -36.4      4.857       5191.0  no  \n",
            "2          93.994          -36.4      4.857       5191.0  no  \n",
            "3          93.994          -36.4      4.857       5191.0  no  \n",
            "4          93.994          -36.4      4.857       5191.0  no  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the dataset\n",
        "data.to_csv('/content/drive/My Drive/ML Coursework/bank_additional_full_cleaned.csv', index=False)"
      ],
      "metadata": {
        "id": "X-yBXvDRPVZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Encoding categorical variables"
      ],
      "metadata": {
        "id": "-UQlZOHBWoG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ML Coursework/bank_additional_full_cleaned.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Displaying initial information about the dataset\n",
        "print(\"Dataset before encoding:\")\n",
        "print(data.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpeUJe_GXLRN",
        "outputId": "330b59c4-82db-4456-f6eb-2eab777a3cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset before encoding:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41176 entries, 0 to 41175\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             41176 non-null  int64  \n",
            " 1   job             41176 non-null  object \n",
            " 2   marital         41176 non-null  object \n",
            " 3   education       41176 non-null  object \n",
            " 4   default         41176 non-null  object \n",
            " 5   housing         41176 non-null  object \n",
            " 6   loan            41176 non-null  object \n",
            " 7   contact         41176 non-null  object \n",
            " 8   month           41176 non-null  object \n",
            " 9   day_of_week     41176 non-null  object \n",
            " 10  duration        41176 non-null  int64  \n",
            " 11  campaign        41176 non-null  int64  \n",
            " 12  pdays           41176 non-null  int64  \n",
            " 13  previous        41176 non-null  int64  \n",
            " 14  poutcome        41176 non-null  object \n",
            " 15  emp.var.rate    41176 non-null  float64\n",
            " 16  cons.price.idx  41176 non-null  float64\n",
            " 17  cons.conf.idx   41176 non-null  float64\n",
            " 18  euribor3m       41176 non-null  float64\n",
            " 19  nr.employed     41176 non-null  float64\n",
            " 20  y               41176 non-null  object \n",
            "dtypes: float64(5), int64(5), object(11)\n",
            "memory usage: 6.6+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "                       'contact', 'month', 'day_of_week', 'poutcome']\n",
        "\n",
        "# Performing one-hot encoding for all categorical variables/features\n",
        "data_encoded = pd.get_dummies(data, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Displaying information after encoding\n",
        "print(\"\\nDataset after encoding:\")\n",
        "print(data_encoded.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbsHfpIEWzgc",
        "outputId": "64358a85-f27f-413a-ffa7-fe853cacc2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset after encoding:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41176 entries, 0 to 41175\n",
            "Data columns (total 50 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   age                            41176 non-null  int64  \n",
            " 1   duration                       41176 non-null  int64  \n",
            " 2   campaign                       41176 non-null  int64  \n",
            " 3   pdays                          41176 non-null  int64  \n",
            " 4   previous                       41176 non-null  int64  \n",
            " 5   emp.var.rate                   41176 non-null  float64\n",
            " 6   cons.price.idx                 41176 non-null  float64\n",
            " 7   cons.conf.idx                  41176 non-null  float64\n",
            " 8   euribor3m                      41176 non-null  float64\n",
            " 9   nr.employed                    41176 non-null  float64\n",
            " 10  y                              41176 non-null  object \n",
            " 11  job_blue-collar                41176 non-null  bool   \n",
            " 12  job_entrepreneur               41176 non-null  bool   \n",
            " 13  job_housemaid                  41176 non-null  bool   \n",
            " 14  job_management                 41176 non-null  bool   \n",
            " 15  job_retired                    41176 non-null  bool   \n",
            " 16  job_self-employed              41176 non-null  bool   \n",
            " 17  job_services                   41176 non-null  bool   \n",
            " 18  job_student                    41176 non-null  bool   \n",
            " 19  job_technician                 41176 non-null  bool   \n",
            " 20  job_unemployed                 41176 non-null  bool   \n",
            " 21  marital_married                41176 non-null  bool   \n",
            " 22  marital_single                 41176 non-null  bool   \n",
            " 23  education_basic.6y             41176 non-null  bool   \n",
            " 24  education_basic.9y             41176 non-null  bool   \n",
            " 25  education_high.school          41176 non-null  bool   \n",
            " 26  education_illiterate           41176 non-null  bool   \n",
            " 27  education_professional.course  41176 non-null  bool   \n",
            " 28  education_university.degree    41176 non-null  bool   \n",
            " 29  education_unknown              41176 non-null  bool   \n",
            " 30  default_unknown                41176 non-null  bool   \n",
            " 31  default_yes                    41176 non-null  bool   \n",
            " 32  housing_yes                    41176 non-null  bool   \n",
            " 33  loan_yes                       41176 non-null  bool   \n",
            " 34  contact_telephone              41176 non-null  bool   \n",
            " 35  month_aug                      41176 non-null  bool   \n",
            " 36  month_dec                      41176 non-null  bool   \n",
            " 37  month_jul                      41176 non-null  bool   \n",
            " 38  month_jun                      41176 non-null  bool   \n",
            " 39  month_mar                      41176 non-null  bool   \n",
            " 40  month_may                      41176 non-null  bool   \n",
            " 41  month_nov                      41176 non-null  bool   \n",
            " 42  month_oct                      41176 non-null  bool   \n",
            " 43  month_sep                      41176 non-null  bool   \n",
            " 44  day_of_week_mon                41176 non-null  bool   \n",
            " 45  day_of_week_thu                41176 non-null  bool   \n",
            " 46  day_of_week_tue                41176 non-null  bool   \n",
            " 47  day_of_week_wed                41176 non-null  bool   \n",
            " 48  poutcome_nonexistent           41176 non-null  bool   \n",
            " 49  poutcome_success               41176 non-null  bool   \n",
            "dtypes: bool(39), float64(5), int64(5), object(1)\n",
            "memory usage: 5.0+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the encoded dataset\n",
        "data_encoded.to_csv('/content/drive/My Drive/ML Coursework/bank_additional_full_encoded.csv', index=False)"
      ],
      "metadata": {
        "id": "R1bb9E1SbduZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Standardization (Z-Score Normalization)"
      ],
      "metadata": {
        "id": "MmnNqOTSGw5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "Y0SwCIZEG30l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ML Coursework/bank_additional_full_encoded.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Separating the features and the target variable\n",
        "X = data.drop('y', axis=1)  # Dropping the target variable\n",
        "y = data['y']  # Extracting the target variable\n",
        "\n",
        "\n",
        "numerical_columns = ['age', 'campaign', 'pdays', 'previous',\n",
        "                     'emp.var.rate', 'cons.price.idx',\n",
        "                     'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
        "\n",
        "# Initializing the StandardScaler to standardize features to have a mean of 0 and standard deviation of 1\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Creating a copy of the dataset\n",
        "X_standardized = X.copy()\n",
        "X_standardized[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
        "\n",
        "# Adding the target variable back\n",
        "X_standardized['y'] = y"
      ],
      "metadata": {
        "id": "SQ_Z_CFvgvei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the dataset\n",
        "X_standardized.to_csv('/content/drive/My Drive/ML Coursework/bank_additional_full_standardized.csv', index=False)"
      ],
      "metadata": {
        "id": "5VUNz2ZBjPHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Removing the \"duration\" feature"
      ],
      "metadata": {
        "id": "uGf-YnaB7Hb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ML Coursework/bank_additional_full_standardized.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Removing the 'duration' feature as it directly correlates with the target variable\n",
        "data = data.drop('duration', axis=1)"
      ],
      "metadata": {
        "id": "xqZMXt_G7Msp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the dataset\n",
        "data.to_csv('/content/drive/My Drive/ML Coursework/bank_additional_full_final.csv', index=False)"
      ],
      "metadata": {
        "id": "KwHrtkk77leE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Handling class imbalance"
      ],
      "metadata": {
        "id": "O-P1NRpkDdao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking whether imbalance exists\n",
        "\n",
        "file_path = '/content/drive/My Drive/ML Coursework/bank_additional_full_final.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Checking the class distribution for the target variable 'y'\n",
        "class_distribution = data['y'].value_counts()\n",
        "print(\"Class Distribution:\")\n",
        "print(class_distribution)\n",
        "\n",
        "# Calculating the percentage of imbalance\n",
        "percentage_no = (class_distribution['no'] / len(data)) * 100\n",
        "percentage_yes = (class_distribution['yes'] / len(data)) * 100\n",
        "print(f\"\\nPercentage of 'no': {percentage_no:.2f}%\")\n",
        "print(f\"Percentage of 'yes': {percentage_yes:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-Q62ziZDmED",
        "outputId": "c6838712-699f-48ed-cb35-726917fecbca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "y\n",
            "no     36537\n",
            "yes     4639\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage of 'no': 88.73%\n",
            "Percentage of 'yes': 11.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "wiMWK7SrjJhc"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/ML Coursework/bank_additional_full_final.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "X = data.drop('y', axis=1)\n",
        "y = data['y']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Applying SMOTE to the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Checking class distribution after applying SMOTE\n",
        "print(\"\\nClass distribution after handling imbalance:\")\n",
        "print(Counter(y_train_smote))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRFBYneKjXaU",
        "outputId": "90b0131f-0fd7-4f56-c5ac-8ccd44120a31"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution after handling imbalance:\n",
            "Counter({'no': 29229, 'yes': 29229})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the neural network"
      ],
      "metadata": {
        "id": "y1KoSkxL5i7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ],
      "metadata": {
        "id": "Owc7Ls4N5TEd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the neural network\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train_smote.shape[1],)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "5xEXJyZtv2Kr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "AzleiyCAv4HM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting target variable to numeric format\n",
        "y_train_smote = y_train_smote.map({'yes': 1, 'no': 0})\n",
        "y_test = y_test.map({'yes': 1, 'no': 0})"
      ],
      "metadata": {
        "id": "WEVrC-ijx45G"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = model.fit(X_train_smote, y_train_smote,\n",
        "                    validation_split=0.2,  # 20% of training data as validation set\n",
        "                    epochs=30,\n",
        "                    batch_size=64,\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlP4bM1Fv5y7",
        "outputId": "709d7f34-41d2-4f01-961f-fcc8c5b9fa3a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.5170 - val_accuracy: 0.6848 - val_loss: 0.5679\n",
            "Epoch 2/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.8069 - loss: 0.4397 - val_accuracy: 0.6924 - val_loss: 0.5744\n",
            "Epoch 3/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8235 - loss: 0.4021 - val_accuracy: 0.7584 - val_loss: 0.4162\n",
            "Epoch 4/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.3830 - val_accuracy: 0.7375 - val_loss: 0.4894\n",
            "Epoch 5/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3744 - val_accuracy: 0.7504 - val_loss: 0.4443\n",
            "Epoch 6/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 0.3621 - val_accuracy: 0.7502 - val_loss: 0.4778\n",
            "Epoch 7/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3519 - val_accuracy: 0.7529 - val_loss: 0.4810\n",
            "Epoch 8/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.3424 - val_accuracy: 0.7475 - val_loss: 0.4744\n",
            "Epoch 9/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8513 - loss: 0.3374 - val_accuracy: 0.7804 - val_loss: 0.4103\n",
            "Epoch 10/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.3283 - val_accuracy: 0.7843 - val_loss: 0.3846\n",
            "Epoch 11/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3278 - val_accuracy: 0.7801 - val_loss: 0.4177\n",
            "Epoch 12/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3270 - val_accuracy: 0.8017 - val_loss: 0.3754\n",
            "Epoch 13/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3121 - val_accuracy: 0.8366 - val_loss: 0.2998\n",
            "Epoch 14/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.3114 - val_accuracy: 0.8298 - val_loss: 0.3371\n",
            "Epoch 15/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8606 - loss: 0.3129 - val_accuracy: 0.8254 - val_loss: 0.3321\n",
            "Epoch 16/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3019 - val_accuracy: 0.8269 - val_loss: 0.3229\n",
            "Epoch 17/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.8694 - loss: 0.3010 - val_accuracy: 0.8220 - val_loss: 0.3664\n",
            "Epoch 18/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.2955 - val_accuracy: 0.8160 - val_loss: 0.3575\n",
            "Epoch 19/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8742 - loss: 0.2956 - val_accuracy: 0.8266 - val_loss: 0.3302\n",
            "Epoch 20/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8739 - loss: 0.2959 - val_accuracy: 0.8117 - val_loss: 0.3753\n",
            "Epoch 21/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 0.2897 - val_accuracy: 0.8403 - val_loss: 0.3101\n",
            "Epoch 22/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8743 - loss: 0.2891 - val_accuracy: 0.8470 - val_loss: 0.3163\n",
            "Epoch 23/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8796 - loss: 0.2829 - val_accuracy: 0.8275 - val_loss: 0.3482\n",
            "Epoch 24/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8781 - loss: 0.2808 - val_accuracy: 0.8122 - val_loss: 0.3513\n",
            "Epoch 25/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.2827 - val_accuracy: 0.8575 - val_loss: 0.2961\n",
            "Epoch 26/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8785 - loss: 0.2800 - val_accuracy: 0.8486 - val_loss: 0.3135\n",
            "Epoch 27/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8821 - loss: 0.2722 - val_accuracy: 0.8379 - val_loss: 0.3371\n",
            "Epoch 28/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2713 - val_accuracy: 0.8641 - val_loss: 0.2867\n",
            "Epoch 29/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.2716 - val_accuracy: 0.8555 - val_loss: 0.2972\n",
            "Epoch 30/30\n",
            "\u001b[1m731/731\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.2676 - val_accuracy: 0.8544 - val_loss: 0.2924\n"
          ]
        }
      ]
    }
  ]
}